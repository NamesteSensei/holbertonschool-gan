# ğŸ§  Deep Convolutional Generative Adversarial Network (DCGAN) â€” MNIST Project

## ğŸ¯ Project Overview
This project implements and experiments with a **Deep Convolutional GAN (DCGAN)** trained on the **MNIST dataset** using **PyTorch**.  
The objective is to generate realistic handwritten digits by training two neural networks â€” a **Generator** and a **Discriminator** â€” in an adversarial setup.

We used **Weights & Biases (W&B)** to track all experiment runs, visualize training metrics, and log generated samples.

---

## ğŸ§© Directory Structure
dcgan/
â”œâ”€â”€ configs/ # Configuration files (YAML/JSON for future experiments)
â”œâ”€â”€ data/ # Dataset and preprocessing scripts
â”œâ”€â”€ experiments/ # Jupyter notebooks for training and analysis
â”‚ â””â”€â”€ baseline_dcgan_mnist.ipynb
â”œâ”€â”€ logs/ # Training logs and sample outputs
â”œâ”€â”€ models/ # Saved trained models
â”‚ â”œâ”€â”€ generator_trained.pth
â”‚ â””â”€â”€ discriminator_trained.pth
â”œâ”€â”€ utils/ # Helper functions and scripts
â””â”€â”€ README.md # Project documentation


---

## âš™ï¸ Experiments Conducted

| Experiment | Description | Key Observations |
|-------------|-------------|------------------|
| **Baseline DCGAN** | Standard architecture, trained for 5 epochs | Generator begins forming digit-like shapes around epoch 3 |
| **Architecture Variation** | Adjusted filter sizes and feature maps | More detailed outputs but slower convergence |
| **Hyperparameter Tuning** | Changed learning rate and batch size | Lower LR improved stability; higher batch sizes led to smoother loss curves |
| **Precision Experiment** | Tested float16 (mixed precision) | Improved speed, minor loss instability |

---

## ğŸ“Š Weights & Biases (W&B) Dashboard
All runs, metrics, and generated images are logged here:

ğŸ”— **[View Project Dashboard](https://wandb.ai/namestesensei-self/dcgan-mnist)**

Example run (Baseline DCGAN):  
ğŸ”— **[Baseline Run â€“ DCGAN MNIST](https://wandb.ai/namestesensei-self/dcgan-mnist)**

---

## ğŸ“¦ Model Artifacts
Trained models are stored in the `/models` directory:

- ğŸ§  `generator_trained.pth`
- ğŸ§© `discriminator_trained.pth`

You can reload them using:
```python
gen.load_state_dict(torch.load("models/generator_trained.pth"))
disc.load_state_dict(torch.load("models/discriminator_trained.pth"))

